{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1) Random Forest is an ensemble machine learning technique capable of performing both regression and classification tasks using multiple decision trees and a statistical technique called <b>Bagging (Bootstrap Aggregation)</b><br>\n",
    "2) A Random Forest uses two key concepts that give it the name random:<br>\n",
    "<b>\n",
    "a) Random sampling of training observations (rows) when building trees.<br>\n",
    "b) Random subsets of features (columns) for splitting nodes.<br>\n",
    "</b>\n",
    "3) Random forest builds multiple decision trees and merge their predictions together to get a more accurate and stable prediction rather than relying on individual decision trees.<br>\n",
    "4) Random forest, like its name implies, consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest generates a class prediction and the class with the most votes becomes our model’s prediction.<br>\n",
    "5) <b>Random Forest Intuition </b>- A large number of relatively uncorrelated models (trees) operating as a committee will outperform any of the individual constituent models.<br>\n",
    "6) It uses Bootstrapping (selection with replacement) to select random subsets of records and/or columns for creating individual decision trees. It means that some samples might be used multiple times in a single tree.<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example\n",
    "1) There are 100 rows of data<br>\n",
    "2) The target variable(y) has 2 categories - A and B<br>\n",
    "3) In Random Forest, we are constructing 7 Decision Trees<br>\n",
    "4) Suppose out of 7 DT (DT1,DT2,......,DT7), row 37 is a part of DT1, DT3, DT4, DT5, DT6.<br>\n",
    "5) Predictions generated by Decision Trees for row no 37 are:<br>\n",
    "        \n",
    "       DT1 -> A\n",
    "       DT3 -> B\n",
    "       DT4 -> A\n",
    "       DT5 -> A\n",
    "       DT6 -> B\n",
    "6) Prediction out of Random Forest for row no 37 is mode of these predictions (3A and 2B) -> Majority Voting(3,2) = 3<br>\n",
    "7) Prediction for Row no 37 is Category A according to Random Forest.\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping\n",
    "Bootstrapping is randomly selecting samples from training data with replacement. The samples so generated are called as bootstrap samples.\n",
    "\n",
    "<img src=\"bootstrap.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "<img src=\"bagging1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working of Random Forest\n",
    "\n",
    "1)\tSelect random samples from a given dataset.<br>\n",
    "2)\tConstruct a decision tree for each sample and get a prediction result from each decision tree.<br>\n",
    "3)\tPerform a vote for each predicted result.<br>\n",
    "4)\tSelect the prediction result with the most votes as the final prediction.<br>\n",
    "\n",
    "a)\tThe random forest combines hundreds or thousands of decision trees, trains each one on a slightly different set of the observations, splitting nodes in each tree considering a limited number of the features. <br>\n",
    "b)\tThe final predictions of the random forest are made by averaging the predictions of each individual tree. <br>\n",
    "c)\tThe random forest is a classification algorithm consisting of many decisions trees. It uses bagging and feature randomness when building each individual tree to try to create an uncorrelated forest of trees whose prediction by committee is more accurate than that of any individual tree. <br>\n",
    "\n",
    "<img src=\"rf1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyperParameters of RandomForest\n",
    "\n",
    "<b>1) n_estimators :</b>  This is the number of trees you want to build before taking the maximum voting or averages of predictions. Higher number of trees give you better performance but makes your code slower.\n",
    "\n",
    "<b>2) min_samples_split :</b> The minimum number of samples required to split an internal node. The algorithm keeps splitting the nodes as long as a node has more samples (data points) than the number specified with min_samples_split parameter.\n",
    "\n",
    "<b>3) criterion:</b> gini or entropy for classification and mse for regression.\n",
    "\n",
    "<b>4) max_features:</b> These are the maximum number of features Random Forest is allowed to try in individual tree. The values it can have are:-<br>\n",
    "    \n",
    "    a) Auto/None : This will simply take all the features which make sense in every tree. Here we simply do not put any restrictions on the individual tree.\n",
    "    b) sqrt : This option will take square root of the total number of features in individual run. For instance, if the total number of variables are 100, we can only take 10 of them in individual tree. “log2” is another similar type of option for max_features.\n",
    "    c) 0.x : This option allows the random forest to take x% of variables in individual run. We can assign and value in a format “0.x” where we want x% of features to be considered.\n",
    "\n",
    "<b>5) bootstrap :</b>  True/False. If it is set to true samples are drawn with replacement and samples are drawn without replacement if bootstrap is set to false\n",
    "\n",
    "<b> 6) oob_score :</b> True/False. (oob - Out of Bag dataset)\n",
    "Whether to use out-of-bag samples to estimate the generalization accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
